{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mKK4Rd8vhPS"
      },
      "source": [
        "#  **ICT303 - Assignment 2**\n",
        "\n",
        "**Your name:  Harithaa Kannan**\n",
        "\n",
        "**Student ID: 34409493**\n",
        "\n",
        "**Email: somethingtothecore@gmail.com**\n",
        "\n",
        "In this assignment, you will build a deep learning model for identifying $120$ different breeds of dogs. Similar to the previous assignment, you will use real images from the [Kaggle competition](https://www.kaggle.com/c/dog-breed-identification).\n",
        "\n",
        "In this assignment, your are required to use a ResNet network. You can use ResNet implementation provided in PyTorch. Note however  that there are many versions of ResNet (they differ in terms of number of layers). Your task is to find the best configuration that gives the best performance.\n",
        "\n",
        "The rule is similar to the previous assignment:\n",
        "\n",
        "1. Develop a better model to reduce the recognition error.  \n",
        "2. Submit your results to Kaggle and take a sceenshot of your score. Then insert here the screenshot of your result.\n",
        "\n",
        "It is important that you start as earlier as possible. Tuning hyper-parameters takes time, and Kaggle limits the number of submissions per day.\n",
        "\n",
        "The top 3 students in the Kaggle ranking will be invited for a coffee!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Obtaining and Organizing the Data Set**\n",
        "\n",
        "The competition data is divided into a training set and testing set:\n",
        "- The training set contains $10,222$ color images.\n",
        "- The testing set contains $10,357$ color images.\n",
        "\n",
        "The images in both sets are in JPEG format. Each image contains three channels (R, G and B). The images have  different heights and widths.\n",
        "\n",
        "There are $120$ breeds of dogs in the training set, e.g., *Labradors, Poodles, Dachshunds,\n",
        "Samoyeds, Huskies, Chihuahuas, and Yorkshire Terriers*."
      ],
      "metadata": {
        "id": "QYa8reVO9OBQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1. Downloading the Data Set**\n",
        "\n",
        "After logging in to Kaggle, click on the “Data” tab on the dog breed identification competition webpage and download:\n",
        "- the training data set `train.zip` and their corresponing labels `label.csv.zip`,\n",
        "- the testing data set `test.zip`,\n",
        "\n",
        "After downloading the files, place them in the three paths below:\n",
        "- kaggle_dog/train.zip\n",
        "- kaggle_dog/test.zip\n",
        "- kaggle_dog/labels.csv.zip\n",
        "\n",
        "Run the code below to extract the data."
      ],
      "metadata": {
        "id": "he01H0Em-AlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "data_dir = './kaggle_dog'\n",
        "\n",
        "zipfiles = ['train.zip', 'test.zip', 'labels.csv.zip']\n",
        "for f in zipfiles:\n",
        "  with zipfile.ZipFile(data_dir + '/' + f, 'r') as z:\n",
        "    z.extractall(data_dir)"
      ],
      "metadata": {
        "id": "nQl2ToXAuuIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2. Organizing the Data Set**\n",
        "\n",
        "Next, we define the reorg_train_valid function to split the validation set from the original Kaggle competition training set. The parameter valid_ratio in this function is the ratio of the number of examples of each dog breeds in the validation set to the number of examples of the\n",
        "breed with the least examples (66) in the original training set.\n",
        "\n",
        "After organizing the data, images of the same breed will be placed in the same folder so that we can read them later."
      ],
      "metadata": {
        "id": "B6lWE7t9-Cfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's first install d2l package, since we will need some functions from this package\n",
        "! pip install d2l==1.0.0a1.post0"
      ],
      "metadata": {
        "id": "cl3UvrUBw70C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import d2l\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "def reorg_train_valid(data_dir, train_dir, input_dir, valid_ratio, idx_label):\n",
        "  # The number of examples of the least represented breed in the training set.\n",
        "  min_n_train_per_label = (\n",
        "      collections.Counter(idx_label.values()).most_common()[:-2:-1][0][1])\n",
        "\n",
        "  # The number of examples of each breed in the validation set.\n",
        "  n_valid_per_label = math.floor(min_n_train_per_label * valid_ratio)\n",
        "  label_count = {}\n",
        "  for train_file in os.listdir(os.path.join(data_dir, train_dir)):\n",
        "    idx = train_file.split('.')[0]\n",
        "    label = idx_label[idx]\n",
        "\n",
        "    d2l.mkdir_if_not_exist([data_dir, input_dir, 'train_valid', label])\n",
        "\n",
        "    shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
        "                os.path.join(data_dir, input_dir, 'train_valid', label))\n",
        "\n",
        "    if label not in label_count or label_count[label] < n_valid_per_label:\n",
        "      d2l.mkdir_if_not_exist([data_dir, input_dir, 'valid', label])\n",
        "      shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
        "                  os.path.join(data_dir, input_dir, 'valid', label))\n",
        "      label_count[label] = label_count.get(label, 0) + 1\n",
        "\n",
        "    else:\n",
        "      d2l.mkdir_if_not_exist([data_dir, input_dir, 'train', label])\n",
        "      shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
        "                  os.path.join(data_dir, input_dir, 'train', label))"
      ],
      "metadata": {
        "id": "B5YtyOyyvrS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `reorg_dog_data` function below is used to read the training data labels, segment the validation set, and organize the training set."
      ],
      "metadata": {
        "id": "hO1gPYXCyX_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reorg_dog_data(data_dir, label_file, train_dir, test_dir, input_dir, valid_ratio):\n",
        "  # Read the training data labels.\n",
        "  with open(os.path.join(data_dir, label_file), 'r') as f:\n",
        "    # Skip the file header line (column name).\n",
        "    lines = f.readlines()[1:]\n",
        "    tokens = [l.rstrip().split(',') for l in lines]\n",
        "    idx_label = dict(((idx, label) for idx, label in tokens))\n",
        "\n",
        "  reorg_train_valid(data_dir, train_dir, input_dir, valid_ratio, idx_label)\n",
        "\n",
        "  # Organize the training set.\n",
        "  d2l.mkdir_if_not_exist([data_dir, input_dir, 'test', 'unknown'])\n",
        "  for test_file in os.listdir(os.path.join(data_dir, test_dir)):\n",
        "    shutil.copy(os.path.join(data_dir, test_dir, test_file),\n",
        "                os.path.join(data_dir, input_dir, 'test', 'unknown'))"
      ],
      "metadata": {
        "id": "gdsp7bSryXbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "During actual training and testing, we would use the entire Kaggle Competition data set and call the reorg_dog_data function to organize the data set. Likewise, we would need to set the batch_size to a larger integer, such as 128."
      ],
      "metadata": {
        "id": "trqywyYRysYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_file, train_dir, test_dir = 'labels.csv', 'train', 'test'\n",
        "input_dir, batch_size, valid_ratio = 'train_valid_test', 128, 0.1\n",
        "reorg_dog_data(data_dir, label_file, train_dir, test_dir, input_dir, valid_ratio)"
      ],
      "metadata": {
        "id": "A3o_SZtRy4qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Image Augmentation**\n",
        "\n",
        "Sometimes, when we do not have enough images to train our deep learning model, we data augmentation to simulate new data. For example, in the case of images, assume we only have $10$ images per class. We can create more instance by applying transformations to these images. For example, if the image is of a standin dog, we can rotate it $90$ and $180$ degrees to create two additional instances of the same dog. We can also scale it, etc.\n",
        "\n",
        "Here are some more image augmentation operations that might be useful.\n",
        "\n",
        "Start by training your model on the data set, the way it is provided. Then, think of the types of transformations you can apply to the training images to improve the performance.\n",
        "\n",
        "You can find more about how to apply transformations to images in this [link](https://pytorch.org/vision/stable/transforms.html)."
      ],
      "metadata": {
        "id": "Mh_N5wsV-FUv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Loading (Reading) the Data Set**"
      ],
      "metadata": {
        "id": "QCUUbgO0-OcV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to previous labs, write here the Python code tat reads the training, validation and test set."
      ],
      "metadata": {
        "id": "HKE7gFVE1Heu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Defining and Training ResNet**\n",
        "\n",
        "Here, you are required to use ResNet to recognise the breed of the dogs in the images. You need to write the class that defines the network, the training class and the code for training the network. You are not required to implement ResNet from scratch. Instead, use PyTorch's implementation of ResNet.\n",
        "\n",
        "Note that there are many versions of ResNet. They differ in the number of layers they use. You are required to test with at least 2 versions and report their respective performances.\n",
        "\n",
        "Note that you are required to follow the good practices when training your network. In particular, you need to look at the loss curves (training and validation losses)."
      ],
      "metadata": {
        "id": "jeeuF3ul-Ucg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Run on the Testing Set and Submit teh Results on Kaggle**\n",
        "\n",
        "Finally, test your trained model on the test set and upload the results to the [Kaggle competition](https://www.kaggle.com/c/dog-breed-identification).\n",
        "\n",
        "You are required to submit a screenshot of your score."
      ],
      "metadata": {
        "id": "mMQsNkhZ-qTw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7. Hints to Improve Your Results**\n",
        "- Try to increase the batch size and the number of epochs.\n",
        "- Try deeper ResNet networks.\n"
      ],
      "metadata": {
        "id": "uCDNmqiL-zqf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Assignmnet 2 code**"
      ],
      "metadata": {
        "id": "YqVABB_GCwqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mEtiO64_CHEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import collections\n",
        "import shutil\n",
        "import os\n",
        "from typing import List\n",
        "\n",
        "def mkdir_if_not_exist(path_list : List[str]):\n",
        "    \"\"\"Make a directory if it does not exist.\"\"\"\n",
        "    path = os.path.join(*path_list)\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def reorg_train_valid(data_dir, train_dir, input_dir, valid_ratio, idx_label):\n",
        "  min_n_train_per_label = (\n",
        "      collections.Counter(idx_label.values()).most_common()[:-2:-1][0][1])\n",
        "\n",
        "  n_valid_per_label = math.floor(min_n_train_per_label * valid_ratio)\n",
        "  label_count = {}\n",
        "  for train_file in os.listdir(os.path.join(data_dir, train_dir)):\n",
        "    idx = train_file.split('.')[0]\n",
        "    label = idx_label[idx]\n",
        "\n",
        "    mkdir_if_not_exist([data_dir, input_dir, 'train_valid', label])\n",
        "\n",
        "    shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
        "                os.path.join(data_dir, input_dir, 'train_valid', label))\n",
        "\n",
        "    if label not in label_count or label_count[label] < n_valid_per_label:\n",
        "      mkdir_if_not_exist([data_dir, input_dir, 'valid', label])\n",
        "      shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
        "                  os.path.join(data_dir, input_dir, 'valid', label))\n",
        "      label_count[label] = label_count.get(label, 0) + 1\n",
        "\n",
        "    else:\n",
        "      mkdir_if_not_exist([data_dir, input_dir, 'train', label])\n",
        "      shutil.copy(os.path.join(data_dir, train_dir, train_file),\n",
        "                  os.path.join(data_dir, input_dir, 'train', label))\n",
        "\n",
        "def reorg_dog_data(data_dir, label_file, train_dir, test_dir, input_dir, valid_ratio):\n",
        "  with open(os.path.join(data_dir, label_file), 'r') as f:\n",
        "    lines = f.readlines()[1:]\n",
        "    tokens = [l.rstrip().split(',') for l in lines]\n",
        "    idx_label = dict(((idx, label) for idx, label in tokens))\n",
        "\n",
        "  reorg_train_valid(data_dir, train_dir, input_dir, valid_ratio, idx_label)\n",
        "\n",
        "  mkdir_if_not_exist([data_dir, input_dir, 'test', 'unknown'])\n",
        "  for test_file in os.listdir(os.path.join(data_dir, test_dir)):\n",
        "    shutil.copy(os.path.join(data_dir, test_dir, test_file),\n",
        "                os.path.join(data_dir, input_dir, 'test', 'unknown'))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "  data_dir, label_file, train_dir, test_dir = '/content/drive/MyDrive/ICT303/dog-breed-identification', 'labels.csv', 'train', 'test'\n",
        "  input_dir, batch_size, valid_ratio = 'train_valid_test', 128, 0.1\n",
        "  reorg_dog_data(data_dir, label_file, train_dir, test_dir, input_dir, valid_ratio)"
      ],
      "metadata": {
        "id": "BogY6iuyl8VL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def accuracy(outputs, labels):\n",
        "    _, predicted = torch.max(outputs, dim=1)\n",
        "    total = labels.size(0)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "tG-c9D_Wl8SH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    total = labels.size(0)\n",
        "    accuracy = correct / total\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "mZRkTwkwCGyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "\n",
        "def accuracy(outputs, labels):\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    total = labels.size(0)\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "class Validator():\n",
        "\n",
        "    def __init__(self, val_folder: Path, val_interval: int = 2) -> None:\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.val_folder = val_folder\n",
        "        self.val_interval = val_interval\n",
        "        self._prepare_data()\n",
        "\n",
        "    def _prepare_data(self):\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "\n",
        "        self.dataset = datasets.ImageFolder(self.val_folder, transform=self.transform)\n",
        "\n",
        "    def validate_model(self, model: torch.nn.Module, criterion, batch_size: int = 32):\n",
        "\n",
        "\n",
        "        assert model is not None, \"Model is not defined\"\n",
        "\n",
        "        dataloader = torch.utils.data.DataLoader(self.dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        model.eval()\n",
        "        total_accuracy = 0.0\n",
        "        running_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch_i, (inputs, labels) in enumerate(dataloader):\n",
        "                inputs = inputs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                batch_accuracy = accuracy(outputs, labels)\n",
        "                total_accuracy += batch_accuracy\n",
        "\n",
        "                running_loss += loss.item()\n",
        "\n",
        "                if (batch_i + 1) % 10 == 0:\n",
        "                    print(f\"Val Step [{batch_i + 1}/{len(dataloader)}], Loss: {running_loss / 10:.4f} Accuracy: {total_accuracy / (batch_i +1):.4f}\")\n",
        "                    running_loss = 0.0\n",
        "\n",
        "            val_metric = total_accuracy / (batch_i + 1)\n",
        "            print(f\"Validation accuracy: {val_metric:.4f}\")\n",
        "            print(\"last output\", self._prediction_to_csv_str(torch.nn.functional.softmax(outputs[0]).detach().cpu().numpy()))\n",
        "\n",
        "            return val_metric\n",
        "\n",
        "    def test_on_folder(self, model: torch.nn.Module, test_folder: Path, output_file: Path, batch_size: int = 64):\n",
        "\n",
        "\n",
        "        if output_file.exists():\n",
        "            print(f\"Output file {output_file} already exists. Exiting...\")\n",
        "            return\n",
        "\n",
        "        print(f\"Testing model on {test_folder}\")\n",
        "\n",
        "        csv_output = \"id,\" + \",\".join(self._get_class_names()) + \"\\n\"\n",
        "        batch_img_tensors = []\n",
        "        batch_img_paths = []\n",
        "        batch_count = 0\n",
        "        total_count = 0\n",
        "        n_test_imgs = len(list(test_folder.iterdir()))\n",
        "        for img_path in test_folder.iterdir():\n",
        "            if img_path.is_file():\n",
        "                img_data = Image.open(img_path)\n",
        "                img_tensor = self.transform(img_data)\n",
        "                img_tensor = img_tensor.unsqueeze(0)\n",
        "                batch_img_tensors.append(img_tensor)\n",
        "                batch_img_paths.append(img_path)\n",
        "\n",
        "                if batch_count == batch_size or total_count == n_test_imgs - 1:\n",
        "                    batch_count = 0\n",
        "                    img_tensor = torch.cat(batch_img_tensors)\n",
        "\n",
        "                    img_tensor = img_tensor.to(self.device)\n",
        "                    outputs = torch.nn.functional.softmax(model(img_tensor), dim=1).cpu().detach().numpy()\n",
        "\n",
        "                    for output, path in zip(outputs, batch_img_paths):\n",
        "                        csv_line = f\"{path.stem},{self._prediction_to_csv_str(output)}\\n\"\n",
        "                        csv_output += csv_line\n",
        "\n",
        "                    batch_img_tensors = []\n",
        "                    batch_img_paths = []\n",
        "\n",
        "                batch_count += 1\n",
        "                total_count += 1\n",
        "\n",
        "        with open(output_file, \"w\") as f:\n",
        "            f.write(csv_output)\n",
        "\n",
        "        print(f\"Saved predictions to {output_file}\")\n",
        "\n",
        "    def _get_class_names(self):\n",
        "        return self.dataset.classes\n",
        "\n",
        "    def _prediction_to_csv_str(self, pred_probs: np.array, sep=\",\") -> str:\n",
        "\n",
        "        result_str = \"\"\n",
        "        for class_prob in pred_probs:\n",
        "            if class_prob < 0:\n",
        "                class_prob *= -1\n",
        "            result_str += f\"{class_prob:.4f}{sep}\"\n",
        "        return result_str[:-1]\n"
      ],
      "metadata": {
        "id": "qUrBQTU_l8MN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "\n",
        "\n",
        "class Trainer():\n",
        "\n",
        "    def __init__(self, train_folder : Path, save_folder : Path, n_epochs : int, batch_size : int, augmetation_transforms) -> None:\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.train_folder = train_folder\n",
        "        self.save_folder = save_folder\n",
        "        self.n_epochs = n_epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.augmetation_transforms = augmetation_transforms\n",
        "        self._prepare_data()\n",
        "        self._prepare_model()\n",
        "\n",
        "    def _prepare_data(self):\n",
        "\n",
        "        transform_steps = [\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224)\n",
        "        ]\n",
        "\n",
        "        if self.augmetation_transforms is not None and len(self.augmetation_transforms) > 0:\n",
        "            transform_steps.extend(self.augmetation_transforms)\n",
        "\n",
        "        transform_steps.append(transforms.ToTensor())\n",
        "        transform_steps.append(transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]))\n",
        "\n",
        "        transform = transforms.Compose(transform_steps)\n",
        "\n",
        "\n",
        "        self.dataset = datasets.ImageFolder(self.train_folder, transform=transform)\n",
        "\n",
        "    def _prepare_model(self):\n",
        "\n",
        "        self.model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "        num_classes = len(self.dataset.classes)\n",
        "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
        "        self.model = self.model.to(self.device)\n",
        "\n",
        "    def load_model_from_file(self, file : Path):\n",
        "        self.model.load_state_dict(torch.load(file))\n",
        "        self.model = self.model.to(self.device)\n",
        "\n",
        "    def train(self, validator : Validator):\n",
        "\n",
        "\n",
        "\n",
        "        dataloader = torch.utils.data.DataLoader(self.dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        # optimizer = optim.AdamW(self.model.parameters(), lr=0.001)\n",
        "        optimizer = optim.SGD(self.model.parameters(), lr=0.001, momentum=0.9)\n",
        "       # optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "        best_val_score = 0.0\n",
        "        for epoch in range(self.n_epochs):\n",
        "            running_loss = 0.0\n",
        "            self.model.train()\n",
        "            for i, (inputs, labels) in enumerate(dataloader):\n",
        "                inputs = inputs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "\n",
        "                outputs = self.model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "\n",
        "                if (i + 1) % 10 == 0:\n",
        "                    print(f\"Epoch [{epoch + 1}/{self.n_epochs}], Step [{i + 1}/{len(dataloader)}], Loss: {running_loss / 10:.4f}\")\n",
        "                    running_loss = 0.0\n",
        "\n",
        "            if (epoch + 1) % validator.val_interval == 0:\n",
        "                val_score = validator.validate_model(self.model, criterion, batch_size=self.batch_size)\n",
        "\n",
        "                if val_score > best_val_score:\n",
        "                    best_val_score = val_score\n",
        "                    torch.save(self.model.state_dict(), self.save_folder / \"best_model.pt\")\n",
        "                    print(\"Best model saved!\")\n",
        "\n",
        "        print(\"Training complete!\")"
      ],
      "metadata": {
        "id": "7U7jtSCQl8JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pathlib import Path\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "data_augementation_steps = [\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    #transforms.RandomRotation(degrees=20),\n",
        "   # transforms.CenterCrop(15),\n",
        "\n",
        "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)\n",
        "]\n",
        "\n",
        "trainer = Trainer(train_folder=Path(\"/content/drive/MyDrive/ICT303/dog-breed-identification/train_valid_test/train\"),\n",
        "                 save_folder=Path(\"/content/drive/MyDrive/ICT303/dog-breed-identification\"),\n",
        "                    n_epochs=10,\n",
        "                    batch_size=128,\n",
        "                    augmetation_transforms=data_augementation_steps\n",
        "                 )\n",
        "validator = Validator(val_folder=Path(\"/content/drive/MyDrive/ICT303/dog-breed-identification/train_valid_test/valid\"), val_interval=1)\n",
        "\n",
        "\n",
        "\n",
        "print(\"start training ...\")\n",
        "trainer.train(validator)\n",
        "trainer.load_model_from_file(Path(\"/content/drive/MyDrive/ICT303/dog-breed-identification/best_model.pt\"))\n",
        "validator.test_on_folder(trainer.model, test_folder=Path(\"/content/drive/MyDrive/ICT303/dog-breed-identification/test\"), output_file=Path(\"test_results.csv\"))"
      ],
      "metadata": {
        "id": "Tk4jRGyaCeMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Screenshot of the result in file called \"test_result\""
      ],
      "metadata": {
        "id": "P1nA0ad9Ec_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is the script for training the deep learning model on a dog bread identification dataset.It uses ResNet-50 architecture , which is a popular conventional neural network architecture(CNN), which is known for its good performance on various image classification tasks."
      ],
      "metadata": {
        "id": "KNVTRX-n1fPA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Break down of the code:\n",
        "\n",
        "First the functions reorg_train_valid and reorg_dog_data for reorganizing the data into train, validation, and test sets are defined.The function reorg_dog_data takes the data directory, label file, train, and test directories, and a validation ratio as input. It separates the data into train, validation, and test folders based on the provided ratio.\n",
        "\n",
        "Then The Validator class is defined to handle the validation process. It takes the validation folder (after reorganizing the data), and validation interval as input. It uses PyTorch's ImageFolder dataset to load the images and apply required transformations for validation.\n",
        "\n",
        "The test_on_folder method in the Validator class is used for testing the model on the test dataset. It loads the test images, performs inference, and saves the predictions to a CSV file.\n",
        "\n",
        "The Trainer class is defined to handle the training process. It takes the train folder, save folder, number of epochs, batch size, and optional data augmentation transformations as input. It uses the ResNet-50 architecture and adapts the last fully connected layer to match the number of classes in the dataset.\n",
        "The training loop iterates through the dataset for the specified number of epochs, using cross-entropy loss and stochastic gradient descent (SGD) as the optimizer.\n",
        "\n",
        "There is  a list of data augmentation transformations defined, such as random horizontal and vertical flips, color jitter, etc. These augmentations help in creating variations of the input data during training, which can lead to better generalization and performance.\n",
        "I have chosen the ones that give better result than others after trying them out.\n",
        "\n",
        "The script creates an instance of the Trainer class and an instance of the Validator class. It then performs the training using the trainer.train(validator) method, which iterates through the dataset and trains the ResNet-50 model.\n",
        "After training, the best model is loaded back from the saved file (best_model.pt) using trainer.load_model_from_file method.\n",
        "The validator.test_on_folder method is used to test the trained model on the test dataset, and the results are saved to test_results.csv.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DHMvfD981fGc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rationale\n",
        "Using the ResNet-50 architecture is a significant advantage, as it has proven to be a powerful and effective CNN architecture for image classification tasks.\n",
        "\n",
        "Data augmentation helps in increasing the size and diversity of the training dataset, which can lead to better generalization and improved model performance on unseen data.\n",
        "\n",
        "The training loop and validation mechanism are well-organized, making it easier to track the training progress and model performance during the training process.\n",
        "\n",
        "The code is structured into different classes, making it modular and easier to reuse for other projects or datasets.\n",
        "\n",
        "The program also saves the best model based on the validation performance, allowing us to use the best-performing model for inference and testing."
      ],
      "metadata": {
        "id": "bKy1C4pG1fB7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best score i got is (score = 0.58074 )\n",
        "I could have gotten a better score with a few more tweaks, but i ran out of compute units. I bought them again for $15 and ran out of them again.\n",
        "Thank you."
      ],
      "metadata": {
        "id": "S5_eSUKjV5i-"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}